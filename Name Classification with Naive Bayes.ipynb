{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Classification with Naive Bayes\n",
    "\n",
    "## Overview\n",
    "\n",
    "Focus of this project is to build a python module, that can determine if a person is Japanese or not, based on their name string. \n",
    "Final product is a class file containing `NameClassifier` class, capable of \n",
    "- loading & preprocessing train and test data\n",
    "- train the model\n",
    "- predict and evaluate the model\n",
    "- save & load trained model for future use\n",
    "\n",
    "The data of name strings with various origin from the world was obtained by using `Faker` library in python. 100000 fake names were created for each class for training and testing purposes. \n",
    "\n",
    "## Libraries / Dependencies\n",
    "\n",
    "Couple python libraries were used to build this class\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- pickle\n",
    "\n",
    "In order to use the class, these libraries and their dependencies need to be installed on your system.\n",
    "\n",
    "## Setup and Locations\n",
    "\n",
    "This class is only tested on Ubuntu Linux 18.04 version, and can be used by importing the class. The class file `model.py` needs to be located in the directory where you intend to use it. Data and saved model file can be located anywhere, as long as you have relative path to them from the class file. However generally it's good idea to keep everything within same or its child's directory. \n",
    "\n",
    "Now the basics are all out of the way, let's get started!\n",
    "\n",
    "## Taking a look at data\n",
    "\n",
    "This module load in the name data as csv file using pandas. You should have separate csv files, each for Japanese and non-Japanese names. \n",
    "\n",
    "In a file, this would look like\n",
    "\n",
    ">Country, Address, name, other col..<br>\n",
    "value1, value2, John Smith, value4\n",
    "\n",
    "**As long as there is a column named `name` with the name data, other columns can also be present.<br> \n",
    "There should always be a white space between first and last name, since the model breaks down into first and last name, and analyze them.**\n",
    "\n",
    "For example, using dataframe, the data might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Names: \n",
      "         code   name\n",
      "47918  jp_JP  小林 知実\n",
      "18845  jp_JP  田辺 英樹\n",
      "38586  jp_JP  吉田 拓真\n",
      "63073  jp_JP   藤本 舞\n",
      "80234  jp_JP  井高 裕太\n",
      "99559  jp_JP   井上 稔\n",
      "20761  jp_JP   小泉 学\n",
      "28726  jp_JP  鈴木 七夏\n",
      "72093  jp_JP   浜田 舞\n",
      "91056  jp_JP  廣川 七夏\n",
      "\n",
      "non-Japanese Names:\n",
      "         code                      name\n",
      "88926  uk_UA               Іван Вишняк\n",
      "8878   cs_CZ       Miloslava Jelínková\n",
      "75355  ru_RU  Михеева Ирина Руслановна\n",
      "18271  en_AU            Sarah Phillips\n",
      "95640  zh_TW                      蔡 雅琪\n",
      "12466  de_DE    Dr. Jovan Hornich MBA.\n",
      "26243  en_US             Shannon Burns\n",
      "38615  es_MX     Ricardo Mateo Nevárez\n",
      "23816  en_CA             Steven Sutton\n",
      "98479  zh_TW                      蘭 心怡\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "j_name = pd.read_csv('data/jp_names.csv')\n",
    "f_name = pd.read_csv('data/f_names.csv')\n",
    "\n",
    "print(\"Japanese Names: \\n\", j_name.sample(10))\n",
    "print(\"\\nnon-Japanese Names:\\n\", f_name.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Preprocessing of data is one of the most important aspect of machine learing. It can boost or ruin the models' performance. \n",
    "Here, since we're dealing with text data, it needs to be encoded into numbers. \n",
    "\n",
    "### Spliting Dataset\n",
    "The dataset is splitted into train and test datasets, for model training and testing.\n",
    "Default ratio is set to \n",
    "> train : test = 70% : 30%\n",
    "\n",
    "This ratio can be modified if necessary.\n",
    "\n",
    "We use `NameClassifier.load_data()` method to load the data and split them into 2 dataset like this...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name data: \n",
      " 41400                       中津川 太郎\n",
      "75092    Мухин Мечислав Измаилович\n",
      "23799                        山岸 涼平\n",
      "36534     Guillermo Aida Santacruz\n",
      "77053      Кулагин Фадей Гордеевич\n",
      "95188                       江古田 裕太\n",
      "48746             Rosaria Barbieri\n",
      "48009                Monia Bellini\n",
      "60666                   Igor Kunka\n",
      "88820                   Яків Юрчук\n",
      "Name: name, dtype: object\n",
      "\n",
      "labels:  [0 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "## import the class\n",
    "from model import NameClassifier\n",
    "\n",
    "# the method will return x_train, x_test, y_train, y_test in the particular order\n",
    "x_train, x_test, y_train, y_test = NameClassifier.load_data('data/jp_names.csv', 'data/f_names.csv', test_size=0.4)\n",
    "print('name data: \\n', x_train.sample(10))\n",
    "print('\\nlabels: ', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model\n",
    "In this simple technique, each word that appear in the dataset are assigned with unique number, so that each text can be expressed as a sequence of the numbers.\n",
    "The sequences are converted into vector with each position / index representing each word, and value expressing the frequency of the occurence of the word.\n",
    "\n",
    "<br>\n",
    "Specifically in this class, word count is utilized with scikit-learn's `CountVectorizer`. \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "The data will be encoded into numpy sparse matrix, and is ready to be fed into the Naive Bayes model\n",
    "\n",
    "\n",
    "## How Naive Bayes works...\n",
    "\n",
    "Brah Brah....\n",
    "\n",
    "Using `Sklearn.naive_bayes.MultinomialNB` class.\n",
    "\n",
    "Encoding names with word count and traning naive bayes are done in `NameClassifer.train()` method, lile...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer and training the model...\n",
      "training completed!\n"
     ]
    }
   ],
   "source": [
    "# First, instantiate the NameClassifer with your choice of name.\n",
    "clf = NameClassifier()\n",
    "\n",
    "# then start training with the training data\n",
    "clf.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Model evaluation was done by testset, with 3 metrics.\n",
    "### accuracy\n",
    "how many data points did the model correclty predicted, regardless of class\n",
    "\n",
    "$$acc = \\frac{TP + TN}{Total Data}$$\n",
    "\n",
    "### precision\n",
    "Out of all predicted Japanese names, how many were actual Japanese names?\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "### recall\n",
    "Out of all actual Japanese names, how many did we predict as Japanese?\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "By using `NameClassifier.evaluate()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.80250000000001%\n",
      "precision: 1.0\n",
      "recall: 0.9960718991621709\n"
     ]
    }
   ],
   "source": [
    "# with test data, this will calculate each metrics, and return a dictionary\n",
    "metrics = clf.evaluate(x_test, y_test)\n",
    "\n",
    "print('accuracy: {}%\\nprecision: {}\\nrecall: {}'.format(metrics['accuracy']*100, metrics['precision'], metrics['recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now let us predict some fake names, using the trained model. This can be done through `NameClassifier.predict()` method, and it accept python list of name strings. <br>\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "some_names = ['渡辺　謙', '木村　拓哉', 'Jack Nicholson', ' 陳　港生']\n",
    "# Only the first 2 are Japanese name, so output should look like [1,1,0,0]\n",
    "pred = clf.predict(some_names)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's having trouble with Chinese characters there!\n",
    "\n",
    "\n",
    "### What about unseen names?\n",
    "\n",
    "\n",
    "Here, let's try to predict with names that were not existing in the training dataset, such as\n",
    "- unseen last / first names\n",
    "- Japanese Names in roman\n",
    "- non-Japanese names in Katakana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "\n",
      "So the name 安倍　晋三 is was not present in the training set.\n",
      "Let us try along with Katakana name.\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# First we'll get word_dictionary that are based on model's training data\n",
    "trained_dict = clf.get_word_dict()\n",
    "print('安倍' in trained_dict.keys())\n",
    "print('晋三' in trained_dict.keys())\n",
    "\n",
    "print('\\nSo the name 安倍　晋三 is was not present in the training set.\\nLet us try along with Katakana name.')\n",
    "pred_anom = clf.predict(['安倍　晋三', 'ジェニファー　ローレンス', 'Jennifer Lawrence'])\n",
    "print(pred_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, model fails to recognize the Japanese name at index = 0. Possible improvement would be to \n",
    "- add more varieties to the training data\n",
    "- different ML algorithm\n",
    "\n",
    "## Saving and Loading the Model\n",
    "\n",
    "- Saving the trained model is easy, just use `NameClassifier.save_model()`\n",
    "- Loading can be done by `NameClassifier.load_model()`\n",
    "\n",
    "Both methods accept `path/to/modelFile/fileName.pickle` as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('saved_model.pickle')\n",
    "clf.load_model('saved_model.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do / future features\n",
    "\n",
    "- document the code better\n",
    "- Multi class classification of names for nationalities/origins\n",
    "- trying out with different algorithms, such as \n",
    "    - Neural nets (RNN?)\n",
    "    - random forest\n",
    "    - SVM\n",
    "- input the names as image data, and use CNN to train it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
