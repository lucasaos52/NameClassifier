{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name data analysis\n",
    "\n",
    "Here I'll be performing EDA on the name dataset generated by Faker module.\n",
    "\n",
    "This is a binary classification problem of determining if a name is of a Japanese origin or not. \n",
    "Therefore I'll start with analyzing Japanese names, \n",
    "\n",
    "## Japanese Names\n",
    "\n",
    "### Full name\n",
    "\n",
    "How many unique names are in a dataset.(`jp_name.csv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code    name\n",
      "0  jp_JP  青山 あすか\n",
      "1  jp_JP  西之園 修平\n",
      "2  jp_JP   三宅 裕樹\n",
      "3  jp_JP   喜嶋 直子\n",
      "4  jp_JP   加納 桃子\n",
      "# of unique full names in whole dataset:  2601\n",
      "number of data points:  100000\n"
     ]
    }
   ],
   "source": [
    "jp_name = pd.read_csv('data/jp_names.csv')\n",
    "print(jp_name.head())\n",
    "print(\"# of unique full names in whole dataset: \", len(jp_name.name.unique()))\n",
    "print('number of data points: ', jp_name.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2.6% of the whole dataset is consists of unique name. No wonder the model was performing amazing with test data, \n",
    "because test data would contain names that are exactly the same.\n",
    "\n",
    "### First and Last name\n",
    "\n",
    "Now tokenizing the name into first and last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jp_JP</td>\n",
       "      <td>青山 あすか</td>\n",
       "      <td>あすか</td>\n",
       "      <td>青山</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jp_JP</td>\n",
       "      <td>西之園 修平</td>\n",
       "      <td>修平</td>\n",
       "      <td>西之園</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jp_JP</td>\n",
       "      <td>三宅 裕樹</td>\n",
       "      <td>裕樹</td>\n",
       "      <td>三宅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jp_JP</td>\n",
       "      <td>喜嶋 直子</td>\n",
       "      <td>直子</td>\n",
       "      <td>喜嶋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jp_JP</td>\n",
       "      <td>加納 桃子</td>\n",
       "      <td>桃子</td>\n",
       "      <td>加納</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code    name first last\n",
       "0  jp_JP  青山 あすか   あすか   青山\n",
       "1  jp_JP  西之園 修平    修平  西之園\n",
       "2  jp_JP   三宅 裕樹    裕樹   三宅\n",
       "3  jp_JP   喜嶋 直子    直子   喜嶋\n",
       "4  jp_JP   加納 桃子    桃子   加納"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jp_name['first'] = jp_name['name'].str.split(\" \").str[1]\n",
    "jp_name['last'] = jp_name['name'].str.split(\" \").str[0]\n",
    "jp_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique first and last names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first names: , total 51\n",
      " ['あすか' '修平' '裕樹' '直子' '桃子' '春香' '京助' '治' '明美' '翼' '知実' '舞' '直人' '稔' '香織'\n",
      " '美加子' '太郎' '千代' '零' '智也' '太一' '七夏' '翔太' '聡太郎' '花子' '健一' '英樹' '裕美子' '結衣'\n",
      " '真綾' '学' '加奈' '和也' 'くみ子' '充' '陽子' '直樹' '幹' '里佳' '浩' '亮介' '裕太' '康弘' '洋介'\n",
      " '晃' '涼平' '拓真' '陽一' '淳' 'さゆり' '篤司']\n",
      "\n",
      "last names: , total 51\n",
      " ['青山' '西之園' '三宅' '喜嶋' '加納' '村山' '山田' '江古田' '大垣' '加藤' '田辺' '鈴木' '井高' '桐山'\n",
      " '伊藤' '廣川' '青田' '中津川' '原田' '木村' '渚' '小林' '渡辺' '松本' '藤本' '宮沢' '小泉' '笹田'\n",
      " '田中' '佐々木' '浜田' '坂本' '山岸' '野村' '津田' '石田' '山本' '吉本' '近藤' '吉田' '高橋' '斉藤'\n",
      " '中島' '宇野' '中村' '山口' '井上' '若松' '工藤' '杉山' '佐藤']\n"
     ]
    }
   ],
   "source": [
    "first_names = jp_name['first'].unique() \n",
    "last_names = jp_name['last'].unique() \n",
    "\n",
    "print('first names: , total {}\\n'.format(len(first_names)), first_names)\n",
    "print('\\nlast names: , total {}\\n'.format(len(last_names)), last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights \n",
    "\n",
    "Comparing to the total number of names in the dataset ( 100000) this is rediculously small numbers of unique last and first names. \n",
    "\n",
    "This means that vast majority of the Japanese names in the dataset are duplicates, which explains the high testing set accuracy (testing set is devided from the faker generated dataset), as well as the model's inability to generalize to unseen names.\n",
    "\n",
    "\n",
    "I'm assuming that the sklearn's CountVectorizer is tokenizing the names into first and last name based on the whitespace (**Check if this is correct**).\n",
    "\n",
    "With Naive Bayes, it's meaningless to train the model with duplicates names IF numbers of unique names are limited and small. <br>\n",
    "\n",
    "\n",
    "**Important**\n",
    "Just have to make sure that the dataset includes top 90% most frequent Last and First Japanese names(don't have to be dataset of names, but can be a dictionary of names/name list)\n",
    "\n",
    "**Unseen Names**<br>\n",
    "Dealing with unseen names, \n",
    "1. recognize if it is unseen name, if so, proceed\n",
    "2. add to Japanese / Foregin namelist according to correct answer\n",
    "    * Human intervention needed here?\n",
    "    \n",
    "**異なる字体**\n",
    "\n",
    "Same kanji has different representation sometimes, causing it to be counted as couple names when they're the same name. \n",
    "> For e.g.\n",
    "斎藤、斉藤、齊藤、齋藤\n",
    "\n",
    "* possible solution is to use `CountVectorizer()`'s  `strip_accents:{ascii, unicode, None}` option to normalize character. \n",
    "\n",
    "## data collection\n",
    "\n",
    "### Japanese\n",
    "\n",
    "**Last Name**\n",
    "* Scrape Last names [here](https://myoji-yurai.net/prefectureRanking.htm;jsessionid=C13440C475D5A9E10ACD0C8C63AF6E6C.jvm1)\n",
    "\n",
    "**First Name**\n",
    "\n",
    "- [Meiji Yasuda Insurance](https://www.meijiyasuda.co.jp/sp/enjoy/ranking/index.html#/year/2018n/9)\n",
    "This one's list of newer weird first names. \n",
    "\n",
    "- [yearly popular name ranking](http://www.tonsuke.com/nebin.html)\n",
    "Yearly one, based on the Yasuda Insurance Data\n",
    "\n",
    "**Kanji**\n",
    "- [人名、常用漢字一覧表](https://kanji.jitenon.jp/cat/jimmei.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
